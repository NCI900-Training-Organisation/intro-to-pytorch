{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cdb801e-e281-476f-b3e9-e470785d3ad9",
   "metadata": {},
   "source": [
    "### Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96127ef4-bb03-492f-81b9-672f74c20b5c",
   "metadata": {},
   "source": [
    "Neural networks are computational models inspired by the human brain, designed to recognize patterns and\n",
    "make decisions based on data. They consist of interconnected layers of nodes, or \"neurons,\" which process\n",
    "and transform input information. Through training, neural networks learn to improve their accuracy in tasks like image recognition, language processing, and more.Neural networks comprise of layers that perform operations on data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "604d5312-0b33-4162-b5f4-551c21732550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49a40db4-da7b-4d24-b707-a39b79d2440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# The jupyter notebook is launched from your $HOME directory.\n",
    "# Change the working directory to the workshop directory\n",
    "# which was created in your username directory under /scratch/vp91\n",
    "os.chdir(os.path.expandvars(\"/scratch/vp91/$USER/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1baab1-a7b6-429e-afa3-822e61da46ad",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "The Pima Indians Diabetes dataset is a popular dataset in the field of machine learning and statistics, particularly for those working on classification problems. \n",
    "\n",
    "Dataset Overview:\n",
    "**Source**: The dataset was created by the National Institute of Diabetes and Digestive and Kidney Diseases (NIDDK) and is available in the UCI Machine Learning Repository.\n",
    "**Purpose**: The dataset is used to predict the onset of diabetes within five years based on diagnostic measures.\n",
    "**Features**: The dataset contains 768 samples, each with 8 features. \n",
    "\n",
    "The features are:\n",
    "\n",
    "1. Pregnancies: Number of times pregnant.\n",
    "2. Glucose: Plasma glucose concentration (mg/dL) a 2 hours in an oral glucose tolerance test.\n",
    "3. Blood Pressure: Diastolic blood pressure (mm Hg) at the time of screening.\n",
    "4. Skin Thickness: Triceps skinfold thickness (mm) measured at the back of the upper arm.\n",
    "5. Insulin: 2-Hour serum insulin (mu U/ml).\n",
    "6. BMI: Body mass index (weight in kg/(height in m)^2).\n",
    "7. Diabetes Pedigree Function: A function that scores likelihood of diabetes based on family history.\n",
    "8. Age: Age of the individual (years).\n",
    "\n",
    "**Outcome**: Whether or not the individual has diabetes (1 for positive, 0 for negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d4b1b9b-bf50-4867-8345-43a7106a25da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6,148,72,35,0,33.6,0.627,50,1\n",
      "1,85,66,29,0,26.6,0.351,31,0\n",
      "8,183,64,0,0,23.3,0.672,32,1\n",
      "1,89,66,23,94,28.1,0.167,21,0\n",
      "0,137,40,35,168,43.1,2.288,33,1\n",
      "5,116,74,0,0,25.6,0.201,30,0\n",
      "3,78,50,32,88,31.0,0.248,26,1\n",
      "10,115,0,0,0,35.3,0.134,29,0\n",
      "2,197,70,45,543,30.5,0.158,53,1\n",
      "8,125,96,0,0,0.0,0.232,54,1\n"
     ]
    }
   ],
   "source": [
    "!head /scratch/vp91/$USER/intro-to-pytorch/data/pima-indians-diabetes.data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ee303492-97bf-4274-9a14-04c1c116f6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/scratch/vp91/jxj900/intro-to-pytorch/data/pima-indians-diabetes.data.csv\n"
     ]
    }
   ],
   "source": [
    "datapath = os.path.expandvars('/scratch/vp91/$USER/intro-to-pytorch/data/pima-indians-diabetes.data.csv')\n",
    "print(datapath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32c13d2-bee6-436c-b838-2c8e04a24ec6",
   "metadata": {},
   "source": [
    "### Curate the dataset\n",
    "Load the dataset, split into features (X) and output (y) variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "222a7a99-2723-486d-9a1e-58d2792c84e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.loadtxt(datapath, delimiter=',')\n",
    "X = dataset[:,0:8] \n",
    "y = dataset[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2a20b9-0c73-4995-b772-0e773cc03c8b",
   "metadata": {},
   "source": [
    "### Convert the data to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3c45e8f-894e-46d3-84c1-25fbca333f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc70a8b-2c37-4c09-bd7c-717d556cb39c",
   "metadata": {},
   "source": [
    "### Defining the Model\n",
    "\n",
    "When designing the model, keep the following points in mind:\n",
    "\n",
    "1. The input features in the input layer must match the input features in the dataset (`X_tensor`).\n",
    "2. A high number of layers can increase computation time, while too few layers may result in poor predictions.\n",
    "3. Each layer should be followed by an activation function.\n",
    "\n",
    "In this example, we will use a 3-layer neural network:\n",
    "\n",
    "1. The input layer expects 8 features.\n",
    "2. The first hidden layer has 12 neurons, followed by a ReLU activation function.\n",
    "3. The second hidden layer has 8 neurons, followed by another ReLU activation function.\n",
    "4. The output layer has one neuron, followed by a sigmoid activation function.\n",
    "\n",
    "The sigmoid function outputs values between 0 and 1, which is exactly what we need."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d8051c-32ee-45c1-b797-58c0e68bbcfb",
   "metadata": {},
   "source": [
    "\n",
    "In PyTorch, neural networks can be defined using different approaches, and two common ones are the Sequential model and the class-based model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81a5b5b-d3bc-434f-9b92-a8571d7599f5",
   "metadata": {},
   "source": [
    "#### Sequential model\n",
    "\n",
    "* The Sequential model is a simple, linear stack of layers where each layer has a single input and output. It is useful for straightforward feedforward networks where layers are applied in a sequential order.\n",
    "* It is easier to use for simple architectures where layers are applied in a linear fashion.\n",
    "* Defined Using: *torch.nn.Sequential*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cb10442-640a-4ded-a81f-6c2607a86bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_model = nn.Sequential(\n",
    "    nn.Linear(8, 12),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8647eb7-799b-42e5-b42d-be699b5e5a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=8, out_features=12, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=12, out_features=8, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (5): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(seq_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a8225d-4528-4a2f-a23e-9285d4ab5c8e",
   "metadata": {},
   "source": [
    "### Class-Based Model\n",
    "\n",
    "The class-based model allows you to define a network by subclassing torch.nn.Module. This approach provides greater flexibility and control, making it suitable for complex models and custom behaviors.\n",
    "\n",
    "* Offers full control over the network architecture, including complex data flows, multiple inputs/outputs, and custom forward methods.\n",
    "* Custom Forward Pass: You can define complex forward passes and control data flow through the network.\n",
    "* Dynamic Behavior: Allows for dynamic computations, such as conditional layers or operations.\n",
    "* Defined Using: Subclass of torch.nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "263d5838-320d-4dad-ac59-e2d95ada7873",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PimaClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden1 = nn.Linear(8, 12)\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.hidden2 = nn.Linear(12, 8)\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.output = nn.Linear(8, 1)\n",
    "        self.act_output = nn.Sigmoid()\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.act1(self.hidden1(x))\n",
    "        x = self.act2(self.hidden2(x))\n",
    "        x = self.act_output(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "289c55b3-f54b-4a79-ba58-5788237aabb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PimaClassifier(\n",
      "  (hidden1): Linear(in_features=8, out_features=12, bias=True)\n",
      "  (act1): ReLU()\n",
      "  (hidden2): Linear(in_features=12, out_features=8, bias=True)\n",
      "  (act2): ReLU()\n",
      "  (output): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (act_output): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class_model = PimaClassifier()\n",
    "print(class_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e889fd5-49a7-4509-a2fc-ef7d5f8c722f",
   "metadata": {},
   "source": [
    "### Define the loss function\n",
    "Binary Cross-Entropy (BCE) Loss: Measures the performance of a classification model whose output is a probability value between 0 and 1. It calculates the difference between the predicted probabilities and the actual binary labels (0 or 1) and penalizes the model more when the predictions are further from the true labels.\n",
    "\n",
    "BCELoss(y', y)=−[ylog(y')+(1−y)log(1−y')]\n",
    "\n",
    "Where, y' is the predicted output and y is the actual otput."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "593672e5-4e14-473d-80f9-2ed00c127729",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518bf03c-0594-494e-bdb3-a41421ac53a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
