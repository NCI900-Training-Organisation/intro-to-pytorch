{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b670ae8e-1350-4be1-8575-df9267fdfae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82a4673-e5e9-4f5f-b7e6-112a8fa1e47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# The jupyter notebook is launched from your $HOME directory.\n",
    "# Change the working directory to the workshop directory\n",
    "# which was created in your username directory under /scratch/vp91\n",
    "os.chdir(os.path.expandvars(\"/scratch/vp91/$USER/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775f4111-d1e2-4cd1-bd2d-a7a1bbb3d21d",
   "metadata": {},
   "source": [
    "PyTorch offers two data primitives—`torch.utils.data.DataLoader` and `torch.utils.data.Dataset`— which \n",
    "facilitate the use of both pre-loaded datasets and custom data.\n",
    "\n",
    "The `Fashion-MNIST` dataset is an example of a pre-loaded curated dataset. It can be loaded using the following parameters:\n",
    "\n",
    "- `root` specifies the path where the training or test data is stored.\n",
    "- `train` indicates whether to load the training or test dataset.\n",
    "- `download=True` will download the data from the internet if it's not available at the specified `root`.\n",
    "- `transform` and `target_transform` define the transformations applied to the features and labels, respectively.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749f1295-2191-40e3-9f7f-8c34589d1a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b818ed5f-c845-4fca-9015-99196f3b937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef48041-ad83-4813-924d-22404d691286",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls data/FashionMNIST/raw/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80984294-a299-4da7-802d-9184706a5f2a",
   "metadata": {},
   "source": [
    "#### Visualizing a sample of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f52a941-cd0e-4665-9e6c-182ffc33c5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "    img, label = training_data[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(labels_map[label])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1d3c91-ba90-469d-9d8b-ab18a7768b84",
   "metadata": {},
   "source": [
    "### Custom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f0bdd5-5521-421f-a56c-532764d123af",
   "metadata": {},
   "source": [
    "What if working with a custom dataset? To illustrate this, we will download a dataset and set it up for\n",
    "use in PyTorch training. The data used for this demonstration is relatively *clean*. In a practical use case, significant time will likely be spent on cleaning and preparing the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727a8d18-c149-4ae7-8791-d301fa83e579",
   "metadata": {},
   "source": [
    "The data:\n",
    "\n",
    "1. There are **3 classes**: pizza, steak, and sushi.\n",
    "2. The data is split into *train* and *test* datasets.\n",
    "3. Both *train* and *test* datasets are further organized into 3 directories, each corresponding to one of the classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c9b050-a64a-45a6-ac46-06b9a0632431",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup path to data folder\n",
    "data_root = Path(\"custom_data/\")\n",
    "image_path = data_root / \"pizza_steak_sushi\"\n",
    "\n",
    "# If the image data doesn't exist, download it and curate it. \n",
    "if not image_path.is_dir():\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Download pizza, steak, sushi data\n",
    "    url = \"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\"\n",
    "    with open(data_root / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
    "        request = requests.get(url)\n",
    "        f.write(request.content)\n",
    "\n",
    "    with zipfile.ZipFile(data_root / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
    "        zip_ref.extractall(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9675e0c5-cffc-4420-a419-eaf3e2198fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls custom_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d51954-2b02-42bb-90e3-121c105e3c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls custom_data/pizza_steak_sushi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8043a6-7ea8-44e7-908d-e0921c9930db",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls custom_data/pizza_steak_sushi/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1425fa36-3c2e-4597-9b78-65516835ac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls custom_data/pizza_steak_sushi/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27f580f-988a-425f-9b3b-e65a23742500",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls custom_data/pizza_steak_sushi/train/pizza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696d0b71-2825-48ed-b84a-cf9519e296f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img = Image.open(\"custom_data/pizza_steak_sushi/train/pizza/928670.jpg\")\n",
    "img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4577dd6b-c581-4dc5-996a-92b7c3a07436",
   "metadata": {},
   "source": [
    "#### Setup train and testing paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b85b56-2ace-4a01-b361-b00ef2b28f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\"\n",
    "\n",
    "train_dir, test_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0bbe2b-edcd-4f07-b715-e42c6d33dc1c",
   "metadata": {},
   "source": [
    "#### Transformation on the data\n",
    "\n",
    "\n",
    "Transform functions in the PyTorch library simplify the application of various data enhancement/manipulation techniques \n",
    "to your input data. These functions enable you to apply multiple changes simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce41688-a909-477c-94ef-010ea6724445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42cbfdb-a5f3-4e07-8beb-e151835902fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write transform for image\n",
    "data_transform = transforms.Compose([\n",
    "    # Resize the images to 64x64\n",
    "    transforms.Resize(size=(64, 64)),\n",
    "    # Flip the images randomly on the horizontal\n",
    "    transforms.RandomHorizontalFlip(p=0.5), # p = probability of flip, 0.5 = 50% chance\n",
    "    # Turn the image into a torch.Tensor\n",
    "    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0 \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53af9e2-b0b9-40ff-9526-a4239600dc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Image.open(\"custom_data/pizza_steak_sushi/train/pizza/928670.jpg\") as f:\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    ax[0].imshow(f) \n",
    "    ax[0].set_title(f\"Original \\nSize: {f.size}\")\n",
    "    ax[0].axis(\"off\")\n",
    "\n",
    "    transformed_image = data_transform(f).permute(1, 2, 0) \n",
    "    ax[1].imshow(transformed_image) \n",
    "    ax[1].set_title(f\"Transformed \\nSize: {transformed_image.shape}\")\n",
    "    ax[1].axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af651bd5-8afa-4c8c-9661-03683f91be8d",
   "metadata": {},
   "source": [
    "#### Loading Image Data Using ImageFolder\n",
    "\n",
    "`ImageFolder` is a generic data loader where images are expected to be organized into separate directories,\n",
    "each corresponding to a different class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245ada1a-e053-4905-aa44-39ef9814fde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ImageFolder to create dataset(s)\n",
    "from torchvision import datasets\n",
    "train_data = datasets.ImageFolder(root=train_dir, # target folder of images\n",
    "                                  transform=data_transform, # transforms to perform on data (images)\n",
    "                                  target_transform=None) # transforms to perform on labels (if necessary)\n",
    "\n",
    "test_data = datasets.ImageFolder(root=test_dir, \n",
    "                                 transform=data_transform)\n",
    "\n",
    "print(f\"Train data:\\n{train_data}\\nTest data:\\n{test_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7ad54a-a8f2-4963-86c3-3150cb68cae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class names as a list\n",
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f14ace-5c56-4a18-b24e-67c34321a2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also get class names as a dict\n",
    "class_dict = train_data.class_to_idx\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede23b28-601c-45ba-a544-ca4d828045ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the lengths\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8d91e6-c12d-4fb1-ab75-c95f1309c995",
   "metadata": {},
   "source": [
    "#### DataLoader\n",
    "\n",
    "\n",
    "In PyTorch, `DataLoader` is a built-in class that offers an efficient and flexible method for loading \n",
    "data into a model for training or inference. It is especially beneficial for managing large datasets that \n",
    "may not fit into memory and for carrying out data augmentation and preprocessing. \n",
    "Data loader combines a dataset and a sampler, and provides an iterable over the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e7b6e1-7ec9-411e-9d3d-422d4d6f8bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ed025b-c14c-4130-97f6-5d00a3757880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn train and test Datasets into DataLoaders\n",
    "from torch.utils.data import DataLoader\n",
    "train_dataloader = DataLoader(dataset=train_data, \n",
    "                              batch_size=8, # how many samples per batch?\n",
    "                              num_workers=1, # how many subprocesses to use for data loading? (higher = more)\n",
    "                              shuffle=True) # shuffle the data?\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_data, \n",
    "                             batch_size=8, \n",
    "                             num_workers=1, \n",
    "                             shuffle=False) # don't usually need to shuffle testing data\n",
    "\n",
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59008e99-69c0-4a5b-ae9a-419273c07841",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = next(iter(train_dataloader))\n",
    "\n",
    "print(f\"Image shape: {img.shape} -> [batch_size, color_channels, height, width]\")\n",
    "print(f\"Label shape: {label.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3c2b18-2162-4d8e-beb9-991093854c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496fb7e6-2727-4ba8-bb2c-6b8460b9565f",
   "metadata": {},
   "source": [
    "#### Custom DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0887d989-49c3-4012-910f-e011340b0059",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = os.path.expandvars('/scratch/vp91/$USER/intro-to-pytorch/data/pima-indians-diabetes.data.csv')\n",
    "\n",
    "# Define the custom Dataset class\n",
    "column_names = [\n",
    "    'Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness',\n",
    "    'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'\n",
    "]\n",
    "\n",
    "# Define the custom Dataset class\n",
    "class PimaDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        # Load the CSV file without header and assign column names\n",
    "        self.data = pd.read_csv(csv_file, header=None, names=column_names)\n",
    "        self.features = self.data.drop('Outcome', axis=1).values\n",
    "        self.labels = self.data['Outcome'].values\n",
    "        \n",
    "        # Convert to PyTorch tensors\n",
    "        self.features_tensor = torch.tensor(self.features, dtype=torch.float32)\n",
    "        self.labels_tensor = torch.tensor(self.labels, dtype=torch.long)\n",
    "        \n",
    "        # Calculate mean and std\n",
    "        self.mean = self.features_tensor.mean(dim=0)\n",
    "        self.std = self.features_tensor.std(dim=0)\n",
    "        \n",
    "        # Normalize the features\n",
    "        self.features_tensor = (self.features_tensor - self.mean) / self.std\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feature = self.features_tensor[idx]\n",
    "        label = self.labels_tensor[idx]\n",
    "        return feature, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c088ccc3-85a1-4a5d-ac9b-7699ff7e91fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PimaDataset(datapath)\n",
    "batch_size = 32\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e8a8d6-f0bc-4618-ad3e-dd3b1a5ca8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features, outcomes = next(iter(data_loader))\n",
    "\n",
    "print(f\"Image shape: {features.shape} -> [batch_size, inputs_features]\")\n",
    "print(f\"Label shape: {outcomes.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24904939-2514-410b-9276-e1f9b9773387",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Use ChatGPT or any other LLMs to create a custom dataloader class for the `pizza_steak_sushi` dataset.\n",
    "\n",
    "Example query - \n",
    "\n",
    "I have a dataset called pizza_steak_sushi. The dataset contains three classes of images - pizza, steak and sushi.\n",
    "\n",
    "When downloaded the dataset is divided into two directories - training and testing. The training directory is divided into three other directories, one for each images classes - pizza, steak and sushi. The training directory is also divided into three other directories, one for each images classes - pizza, steak and sushi.\n",
    "\n",
    "How would you write a custom dataloader class for this? Explain the code generated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8af9b7e-dbcb-425f-984a-65d8fee02bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
