{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "205ea8ba-4865-4511-8a54-14fcd4b22ed0",
   "metadata": {},
   "source": [
    "### Tensors in PyTorch\n",
    "\n",
    "Tensors are specialized data structures used in PyTorch to represent model inputs, outputs, and parameters. While they are conceptually similar to arrays and matrices, they offer additional features such as support for hardware accelerators like GPUs and automatic differentiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "244c9ced-e83c-4c24-a992-f216dfa34456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# The jupyter notebook is launched from your $HOME directory.\n",
    "# Change the working directory to the workshop directory\n",
    "# which was created in your username directory under /scratch/vp91\n",
    "os.chdir(os.path.expandvars(\"/scratch/vp91/$USER/\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20aaadc-e2a0-4a89-9703-b091578b4dc0",
   "metadata": {},
   "source": [
    "### Creating a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "816961f2-0932-47d1-923f-d9743ec8c062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383b7ba2-6d5d-4380-9f36-fb62f6ce1d8f",
   "metadata": {},
   "source": [
    "##### 1. Directly from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2137307c-2fa0-4953-92e3-fcb24408ff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [[1, 2],[3, 4]]\n",
    "x_tensor= torch.tensor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba5f6e9-f0fc-4cee-b48d-660e6267541d",
   "metadata": {},
   "source": [
    "##### 2. From NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "48cd31ef-a810-4aaa-a314-d5f5705e7be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np = np.array(data)\n",
    "x_tensor = torch.from_numpy(x_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d365755-871b-4380-8e36-972799542b5e",
   "metadata": {},
   "source": [
    "##### 3. From another Tensor\n",
    "\n",
    "**torch.rand_like()** returns a tensor with the same size as input that but filled with random numbers from the interval [0,1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62f40f87-637b-4e58-be66-8fe8f8d4b84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1],\n",
      "        [1, 1]])\n"
     ]
    }
   ],
   "source": [
    "x_tensor = torch.ones_like(x_tensor)\n",
    "y_tensor = torch.rand_like(x_tensor, dtype=torch.float) \n",
    "print(x_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e9c4b6-6b85-430d-a793-93521879f671",
   "metadata": {},
   "source": [
    "### Operations on Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59bbc8d-00d1-48cc-bc2c-4443c8ccec31",
   "metadata": {},
   "source": [
    "#### 1. indexing and slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3e7c194-ecea-4ef9-af39-3f563daddc3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([1., 1., 1., 1.])\n",
      "First column: tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x_tensor = torch.ones(4, 4)\n",
    "print(f\"First row: {x_tensor[0]}\")\n",
    "print(f\"First column: {x_tensor[:, 0]}\")\n",
    "print(f\"Last column: {x_tensor[..., -1]}\")\n",
    "x_tensor[:,1] = 0\n",
    "print(x_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe77b93-12ab-475f-81fc-c5a00db24621",
   "metadata": {},
   "source": [
    "#### 2. Concatenate multiple tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b00e821-b480-4f7e-8788-1e983ed1693b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "y_tensor = torch.cat([x_tensor, x_tensor, x_tensor], dim=1)\n",
    "print(y_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77389fec-07d3-4473-a036-af0b9cd39986",
   "metadata": {},
   "source": [
    "#### 3. Arithmetic Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d518086-f064-486e-9e28-29ea15ce7779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tensor = torch.ones(4, 4)\n",
    "\n",
    "# Transpose\n",
    "x_T_tensor = x_tensor.T\n",
    "\n",
    "# Matrix Multiplication\n",
    "y1_tensor = x_tensor @ x_tensor.T\n",
    "y2_tensor = x_tensor.matmul(x_tensor.T)\n",
    "\n",
    "y3_tensor = torch.rand_like(y1_tensor)\n",
    "torch.matmul(x_tensor, x_tensor.T, out=y3_tensor)\n",
    "\n",
    "\n",
    "# Element-wise multiplication\n",
    "z1_tensor = x_tensor * x_tensor\n",
    "z2_tensor = x_tensor.mul(x_tensor)\n",
    "\n",
    "z3_tensor = torch.rand_like(x_tensor)\n",
    "torch.mul(x_tensor, x_tensor, out=z3_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ce833cc-6ff6-4016-96bb-60b70812d584",
   "metadata": {},
   "source": [
    "##### 3. In-place Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "21c046eb-43ad-4259-a2b6-55da191d22db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7934, 0.6413, 0.9885, 0.0340],\n",
       "        [0.2890, 0.5230, 0.1286, 0.1077],\n",
       "        [0.3840, 0.2738, 0.6143, 0.5598],\n",
       "        [0.5460, 0.9349, 0.0589, 0.5723]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tensor = torch.ones(4, 4)\n",
    "\n",
    "# Transpose\n",
    "x_tensor.t_()\n",
    "\n",
    "# Copy\n",
    "y_tensor = torch.rand_like(x_tensor)\n",
    "x_tensor.copy_(y_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73522a1-db18-4fe0-9c07-f27d39f4a992",
   "metadata": {},
   "source": [
    "### NumPy and Tensor\n",
    "Tensors on the **CPU** and NumPy arrays can share memory locations, so modifying one will also affect \n",
    "the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1eee82b4-8f71-4e19-b27e-c47add1714e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([1., 1., 1., 1., 1.])\n",
      "n: [1. 1. 1. 1. 1.]\n",
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n",
      "t: tensor([2., 2., 2., 2., 2.])\n",
      "n: [2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "x_tensor = torch.ones(5) \n",
    "x_np = x_tensor.numpy() # tensor to numpy\n",
    "print(f\"t: {x_tensor}\")\n",
    "print(f\"n: {x_np}\")\n",
    "\n",
    "x_tensor.add_(1)\n",
    "\n",
    "print(f\"t: {x_tensor}\")\n",
    "print(f\"n: {x_np}\")\n",
    "\n",
    "y_np = np.ones(5)\n",
    "z_np = np.zeros(5)\n",
    "y_tensor = torch.from_numpy(y_np) # numpy to tensor\n",
    "\n",
    "np.add(y_np, 1, out=z_np)\n",
    "\n",
    "print(f\"t: {x_tensor}\")\n",
    "print(f\"n: {x_np}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bca47c-de5b-423d-a3d3-153fdaa76bd9",
   "metadata": {},
   "source": [
    "### Moving Tensor to GPU\n",
    "It's always wise to check for GPU availability before performing any GPU operations. If a GPU is available, we can move our tensor to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2199f283-5bbd-4534-b10b-1ed259d56f31",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x_tensor_gpu \u001b[38;5;241m=\u001b[39m \u001b[43mx_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/scratch/vp91/Training-Venv/pytorch/lib/python3.11/site-packages/torch/cuda/__init__.py:314\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    313\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 314\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    318\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "x_tensor_gpu = x_tensor.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663e4316-0e47-4528-bfc0-873b695d3e23",
   "metadata": {},
   "source": [
    "A better approach is to set the default device before starting any computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a9aa52b7-b24d-4686-8798-6ec9582b19f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "y_tensor_gpu = y_tensor.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d565e8-074b-4e10-872f-c6051c38c20b",
   "metadata": {},
   "source": [
    "### Tensor attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "552841ee-fa9d-450e-8ab5-16d7d1d41008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([5])\n",
      "Datatype of tensor: torch.float64\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of tensor: {y_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {y_tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {y_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e90c428-525b-47f2-9dbd-8e017f56e813",
   "metadata": {},
   "source": [
    "*Automatic differentiation* is a key feature that distinguishes tensors from NumPy arrays. This capability\n",
    "is particularly useful in neural networks, where model weights are adjusted during backpropagation based \n",
    "on the gradient of the loss function with respect to each parameter. Tensors support automatic gradient \n",
    "computation for any computational graph. For example, consider the computational graph of a one-layer \n",
    "neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c93bab5-f9bd-439b-a334-cbe482c379ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0752, 0.0121, 0.0481],\n",
      "        [0.0752, 0.0121, 0.0481],\n",
      "        [0.0752, 0.0121, 0.0481],\n",
      "        [0.0752, 0.0121, 0.0481],\n",
      "        [0.0752, 0.0121, 0.0481]])\n",
      "tensor([0.0752, 0.0121, 0.0481])\n"
     ]
    }
   ],
   "source": [
    "x_tensor = torch.ones(5)  # input tensor\n",
    "y_tensor = torch.zeros(3)  # expected output\n",
    "\n",
    "w_tensor = torch.randn(5, 3, requires_grad=True)\n",
    "b_tensor = torch.randn(3, requires_grad=True)\n",
    "\n",
    "z_tensor = torch.matmul(x_tensor, w_tensor) + b_tensor\n",
    "\n",
    "loss_tensor = torch.nn.functional.binary_cross_entropy_with_logits(z_tensor, y_tensor)\n",
    "loss_tensor.backward()\n",
    "\n",
    "print(w_tensor.grad)\n",
    "print(b_tensor.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd58b4d-d46d-4095-a21e-38179685590b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
